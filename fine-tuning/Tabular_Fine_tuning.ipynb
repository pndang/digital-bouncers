{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFjDHpNgPBN2"
      },
      "outputs": [],
      "source": [
        "!pip install langchain pandas openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "dwTnIwRuP3WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv(\"HomeC.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "Grwp4t-UPWxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def row_to_document(row):\n",
        "    document = (\n",
        "        f\"At {row['time']}, the house used {row['use [kW]']} kW and generated {row['gen [kW]']} kW. \"\n",
        "        f\"Room-specific usage: dishwasher {row['Dishwasher [kW]']} kW, fridge {row['Fridge [kW]']} kW, \"\n",
        "        f\"microwave {row['Microwave [kW]']} kW. Weather conditions were {row['summary']} with a temperature of \"\n",
        "        f\"{row['temperature']}Â°C and humidity at {row['humidity']}%. Wind speed was {row['windSpeed']} km/h.\"\n",
        "    )\n",
        "    return document"
      ],
      "metadata": {
        "id": "WSoqbi9SQPOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = data.apply(row_to_document, axis=1).tolist()\n",
        "documents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LIp8AXu5Phy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare fine-tuning data with prompts and responses\n",
        "fine_tuning_data = []\n",
        "\n",
        "for doc in documents:\n",
        "    fine_tuning_data.append({\n",
        "        \"prompt\": f\"Analyze the following data and summarize: {doc}\",\n",
        "        \"response\": \"The house used X kW, generated Y kW, and weather conditions were Z.\"\n",
        "    })\n",
        "\n",
        "# Save as JSON\n",
        "import json\n",
        "with open(\"fine_tuning_data.json\", \"w\") as f:\n",
        "    json.dump(fine_tuning_data, f, indent=2)\n"
      ],
      "metadata": {
        "id": "OzbJiX6tQ0Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n"
      ],
      "metadata": {
        "id": "NJ_2llCMPbQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"gpt2\"  # Replace with your preferred model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load your fine-tuning data\n",
        "dataset = load_dataset(\"json\", data_files=\"fine_tuning_data.json\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_data(example):\n",
        "    return tokenizer(\n",
        "        example[\"prompt\"] + example[\"response\"], truncation=True, padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "# Fine-tuning configuration\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    save_steps=500,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "ZHsNlYpoPeh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8YXWuQVJxi8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}